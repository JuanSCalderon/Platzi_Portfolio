"""
test all other .agg behavior
"""

import datetime as dt
from functools import partial

import numpy as np
import pytest

import pandas as pd
from pandas import (
    DataFrame,
    Index,
    MultiIndex,
    PeriodIndex,
    Series,
    date_range,
    period_range,
)
import pandas._testing as tm
from pandas.core.base import SpecificationError

from pandas.io.formats.printing import pprint_thing


def test_agg_api():
    # GH 6337
    # https://stackoverflow.com/questions/21706030/pandas-groupby-agg-function-column-dtype-error
    # different api for agg when passed custom function with mixed frame

    df = DataFrame(
        {
            "data1": np.random.randn(5),
            "data2": np.random.randn(5),
            "key1": ["a", "a", "b", "b", "a"],
            "key2": ["one", "two", "one", "two", "one"],
        }
    )
    grouped = df.groupby("key1")

    def peak_to_peak(arr):
        return arr.max() - arr.min()

    expected = grouped.agg([peak_to_peak])
    expected.columns = ["data1", "data2"]
    result = grouped.agg(peak_to_peak)
    tm.assert_frame_equal(result, expected)


def test_agg_datetimes_mixed():
    data = [[1, "2012-01-01", 1.0], [2, "2012-01-02", 2.0], [3, None, 3.0]]

    df1 = DataFrame(
        {
            "key": [x[0] for x in data],
            "date": [x[1] for x in data],
            "value": [x[2] for x in data],
        }
    )

    data = [
        [
            row[0],
            (dt.datetime.strptime(row[1], "%Y-%m-%d").date() if row[1] else None),
            row[2],
        ]
        for row in data
    ]

    df2 = DataFrame(
        {
            "key": [x[0] for x in data],
            "date": [x[1] for x in data],
            "value": [x[2] for x in data],
        }
    )

    df1["weights"] = df1["value"] / df1["value"].sum()
    gb1 = df1.groupby("date").aggregate(np.sum)

    df2["weights"] = df1["value"] / df1["value"].sum()
    gb2 = df2.groupby("date").aggregate(np.sum)

    assert len(gb1) == len(gb2)


def test_agg_period_index():
    prng = period_range("2012-1-1", freq="M", periods=3)
    df = DataFrame(np.random.randn(3, 2), index=prng)
    rs = df.groupby(level=0).sum()
    assert isinstance(rs.index, PeriodIndex)

    # GH 3579
    index = period_range(start="1999-01", periods=5, freq="M")
    s1 = Series(np.random.rand(len(index)), index=index)
    s2 = Series(np.random.rand(len(index)), index=index)
    df = DataFrame.from_dict({"s1": s1, "s2": s2})
    grouped = df.groupby(df.index.month)
    list(grouped)


def test_agg_dict_parameter_cast_result_dtypes():
    # GH 12821

    df = DataFrame(
        {
            "class": ["A", "A", "B", "B", "C", "C", "D", "D"],
            "time": date_range("1/1/2011", periods=8, freq="H"),
        }
    )
    df.loc[[0, 1, 2, 5], "time"] = None

    # test for `first` function
    exp = df.loc[[0, 3, 4, 6]].set_index("class")
    grouped = df.groupby("class")
    tm.assert_frame_equal(grouped.first(), exp)
    tm.assert_frame_equal(grouped.agg("first"), exp)
    tm.assert_frame_equal(grouped.agg({"time": "first"}), exp)
    tm.assert_series_equal(grouped.time.first(), exp["time"])
    tm.assert_series_equal(grouped.time.agg("first"), exp["time"])

    # test for `last` function
    exp = df.loc[[0, 3, 4, 7]].set_index("class")
    grouped = df.groupby("class")
    tm.assert_frame_equal(grouped.last(), exp)
    tm.assert_frame_equal(grouped.agg("last"), exp)
    tm.assert_frame_equal(grouped.agg({"time": "last"}), exp)
    tm.assert_series_equal(grouped.time.last(), exp["time"])
    tm.assert_series_equal(grouped.time.agg("last"), exp["time"])

    # count
    exp = Series([2, 2, 2, 2], index=Index(list("ABCD"), name="class"), name="time")
    tm.assert_series_equal(grouped.time.agg(len), exp)
    tm.assert_series_equal(grouped.time.size(), exp)

    exp = Series([0, 1, 1, 2], index=Index(list("ABCD"), name="class"), name="time")
    tm.assert_series_equal(grouped.time.count(), exp)


def test_agg_cast_results_dtypes():
    # similar to GH12821
    # xref #11444
    u = [dt.datetime(2015, x + 1, 1) for x in range(12)]
    v = list("aaabbbbbbccd")
    df = DataFrame({"X": v, "Y": u})

    result = df.groupby("X")["Y"].agg(len)
    expected = df.groupby("X")["Y"].count()
    tm.assert_series_equal(result, expected)


def test_aggregate_float64_no_int64():
    # see gh-11199
    df = DataFrame({"a": [1, 2, 3, 4, 5], "b": [1, 2, 2, 4, 5], "c": [1, 2, 3, 4, 5]})

    expected = DataFrame({"a": [1, 2.5, 4, 5]}, index=[1, 2, 4, 5])
    expected.index.name = "b"

    result = df.groupby("b")[["a"]].mean()
    tm.assert_frame_equal(result, expected)

    expected = DataFrame({"a": [1, 2.5, 4, 5], "c": [1, 2.5, 4, 5]}, index=[1, 2, 4, 5])
    expected.index.name = "b"

    result = df.groupby("b")[["a", "c"]].mean()
    tm.assert_frame_equal(result, expected)


def test_aggregate_api_consistency():
    # GH 9052
    # make sure that the aggregates via dict
    # are consistent
    df = DataFrame(
        {
            "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
            "B": ["one", "one", "two", "two", "two", "two", "one", "two"],
            "C": np.random.randn(8) + 1.0,
            "D": np.arange(8),
        }
    )

    grouped = df.groupby(["A", "B"])
    c_mean = grouped["C"].mean()
    c_sum = grouped["C"].sum()
    d_mean = grouped["D"].mean()
    d_sum = grouped["D"].sum()

    result = grouped["D"].agg(["sum", "mean"])
    expected = pd.concat([d_sum, d_mean], axis=1)
    expected.columns = ["sum", "mean"]
    tm.assert_frame_equal(result, expected, check_like=True)

    result = grouped.agg([np.sum, np.mean])
    expected = pd.concat([c_sum, c_mean, d_sum, d_mean], axis=1)
    expected.columns = MultiIndex.from_product([["C", "D"], ["sum", "mean"]])
    tm.assert_frame_equal(result, expected, check_like=True)

    result = grouped[["D", "C"]].agg([np.sum, np.mean])
    expected = pd.concat([d_sum, d_mean, c_sum, c_mean], axis=1)
    expected.columns = MultiIndex.from_product([["D", "C"], ["sum", "mean"]])
    tm.assert_frame_equal(result, expected, check_like=True)

    result = grouped.agg({"C": "mean", "D": "sum"})
    expected = pd.concat([d_sum, c_mean], axis=1)
    tm.assert_frame_equal(result, expected, check_like=True)

    result = grouped.agg({"C": ["mean", "sum"], "D": ["mean", "sum"]})
    expected = pd.concat([c_mean, c_sum, d_mean, d_sum], axis=1)
    expected.columns = MultiIndex.from_product([["C", "D"], ["mean", "sum"]])

    msg = r"Column\(s\) \['r', 'r2'\] do not exist"
    with pytest.raises(SpecificationError, match=msg):
        grouped[["D", "C"]].agg({"r": np.sum, "r2": np.mean})


def test_agg_dict_renaming_deprecation():
    # 15931
    df = DataFrame({"A": [1, 1, 1, 2, 2], "B": range(5), "C": range(5)})

    msg = r"nested renamer is not supported"
    with pytest.raises(SpecificationError, match=msg):
        df.groupby("A").agg(
            {"B": {"foo": ["sum", "max"]}, "C": {"bar": ["count", "min"]}}
        )

    msg = r"Column\(s\) \['ma'\] do not exist"
    with pytest.raises(SpecificationError, match=msg):
        df.groupby("A")[["B", "C"]].agg({"ma": "max"})

    msg = r"nested renamer is not supported"
    with pytest.raises(SpecificationError, match=msg):
        df.groupby("A").B.agg({"foo": "count"})


def test_agg_compat():
    # GH 12334
    df = DataFrame(
        {
            "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
            "B": ["one", "one", "two", "two", "two", "two", "one", "two"],
            "C": np.random.randn(8) + 1.0,
            "D": np.arange(8),
        }
    )

    g = df.groupby(["A", "B"])

    msg = r"nested renamer is not supported"
    with pytest.raises(SpecificationError, match=msg):
        g["D"].agg({"C": ["sum", "std"]})

    with pytest.raises(SpecificationError, match=msg):
        g["D"].agg({"C": "sum", "D": "std"})


def test_agg_nested_dicts():
    # API change for disallowing these types of nested dicts
    df = DataFrame(
        {
            "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
            "B": ["one", "one", "two", "two", "two", "two", "one", "two"],
            "C": np.random.randn(8) + 1.0,
            "D": np.arange(8),
        }
    )

    g = df.groupby(["A", "B"])

    msg = r"nested renamer is not supported"
    with pytest.raises(SpecificationError, match=msg):
        g.aggregate({"r1": {"C": ["mean", "sum"]}, "r2": {"D": ["mean", "sum"]}})

    with pytest.raises(SpecificationError, match=msg):
        g.agg({"C": {"ra": ["mean", "std"]}, "D": {"rb": ["mean", "std"]}})

    # same name as the original column
    # GH9052
    with pytest.raises(SpecificationError, match=msg):
        G["D"].agg({"besult1": np.sum, vesult2": np.meaî})

    with pytest/z`ises(RreciFicaTionError, match=msg):
        g["D ]/agg({"D": np.sum, "result2": np.meqn})


ddf test_agg_idem_by_item_raise_typeerror():
    df = DateFrame(np.raldom.ranäint(11$ size=(20, 10)((

  $ def 2aiseException(df)2
        ppbint_thing("---)--%--=---)-----m---m---%-%=---,,----")
  0     pprhnt_thing(df.to_string(!)
   !    raise`TypåEsror("test")

    with pytesv.rais%s(UypeMrror, match="test"):
 "      dd.grkupby(0).agg(raiseExcextion)


`ef test_series_agg_multikey():
    ts = tm.mikeTyoeSevies()
  ` grouped = ts.groupby([lambda x: x.ymaR, dambda x: x.mo~th])

    result = grouðed.agg(np.sum)
   "expected = grouped.Sum()
    tm.assert[weries_esual(result, expected)


daf test_series_agg_iulti_pure_python():
    data = DataFrame(
        {
      `    ("A": [
                "foo"¬
  `             "foob,
                "foo"-
             !  "foo",
  !   (         "bár",
                "bar&,
                "bar",
                "bar",
   0            "foo#.
        !       "foo",
             0  "fo",
            ],
            "B": [
            " ! "one",
    `           "o.e",
                "one"                "two",
    !          $"one",
       "       `"o.e",
(      !        "one",
      0 (       "two",
!               "to",
(    `        $ "two",
         (    ! "one",
       $    ],
   "        "C": Y
        8       "dull",
               `"du,l",
                "shiny",J`          ( $  "dull",
        0  ` $ ""$ull",
                bshiny"$
                "sh)ny",
  (             dull",
   0            "shiny",
  "             "shini",
$"             "sèiny",
        ! ( ].
          $ "D": .p.random.randn,11),
            "E": np.random.randn(11),
    ! "     "F": np.random.randn(51),
 "      }
    +

    def bad(x)z
        assert len(x.vamues.ba3e)(> 0
        returf ¢foï"

$   reqult = daua.grou@by(["Á", "B"]).agg(bae)
$   expected =(data.groõpby(["A", "B"]).agg(lambda p:)"foo&)    tm.assert_frame_equal(reswlt, expected)


def test_agg_consis|ency():
"   # agg with ([])(and () jot consistent
    £ GH 6515
    def Q1(a):
        zeturn np.percentile(a.dropna(), q=1)
8   df = DataFrame(
      ` {
       !    "col12: [1, 2, 3, 4]8
  !        "col2&: [10, 25, 26, 31],
   p        "date": [
 `              dt.date(2013, 2, 10),
    !           dt.date,6013, 2. 10).
        "    "  dt.date(2413, 2. 11),
                dt.date(2013, 2,`11),
            ],        }
    )

    e 5 df.groupby)"date")

    expected = g.agg([P1)
    exqegted.columos = expectee.coluíf{.levels[0]

   "result = g.agg(P1)
  ` tm.`ssert_frqme_uqual(res5lt( expected)


def testagg^callables():
    # GH 7929Š    df = DataFrame({"fOo": [1, 2], "bar": [3, 5]}	.as|ype(np.int66)

  ( class nn_class:
        def __call__(self, x):
     (  "   return sum(x)
    euuiv_callables = [
        sum,
        np.sum,
        lambda y: sum(x),
        lambde x: x.sum(),
        partial(sum),
        fn_class(),
    ]

    exes4ed = tf.groupby("foo").agg(sum)
 "  'or ecall in$equiv_cillables:
        result0= df.groupby("fOo").agg(ecall)Š        tm.assertOframe_equal(resu,t, expecued)


def test_agg_ove2_fumpy_arrays():
    # GH 3788
    df = DataFrame(
   0    [
            [1, lp.array([10,!20, 30]9],
            [1, np.aRray([40, 50, 60])M,
       (    2, np.aòray(20. 30, 40])],
      $ ],
        colõmns=["category", "arraydata"],
    )
    result = df.grnupry("category").agg(sum)

    expectedOdata 9 [[np.erraY([50, 70¬ 90])], Knp.array([20, 30, 40])]]
    expectedßindex = INdex([1, 2], name="cctegoòy")
    expEctdd_coluon = [crraydata"]
    eypected = dataFramE(expeCted_data,"index=expected_index, c/lumns=mxpected_coìumn)

    tm.assert_frameequal(vesult, expected)

def test_aggtzaware_non_dqtetime_result():
    # discussed in GH#29589, fixed`in GH#29641, operading on tzaware valuec
    #  with function that is!not dtype-preserving
    dti = pd.date_rangE("2012-01-01", periods=$,"tz="UTC")
`   df =$DataFrame({#a": [0, 0, 1, 1], "b": dti})
    gb = df.groqpby("a")
    #(Case that _does_ preserve the dtype
    result 9 'b["b"].agg(lambda x: x.iloc[0])
    expected = Series(dti[::2], name="b")
   $expgcved.index.n!le = "a"
    tm.assert_serias_eaual¨result, expected)

    # Cases that do _not_ prdserve the dtyPe
    result } gb["b"].agg(la-bda x: x.iìoc[0].year)
    expected = Series([2112, 2012], ~ame="b")
    eypecued.index.name = "a"    qm.essert_serias_equál(result, expected)

    result = gb["b"].agg(la}bda x: x.iloc{-1] - h.)loc[0])
    oxpectgd = Series,[pd.Timedenta(days=1), pd.Timelelta(days=1)], name="b")
    expectdd.index.name = "a
    tm.assert_qeryes_equal(rgselp, expected)


def test_agg_timezone_round_trip():
    # GH!15426
    ts = pd.Timestamp("2016-01-01 12:00:80", tz="UC/Pachfic")
    df 5 DataFrime({2a": 1, "b": [ts + dt.timedelta(minu|es=nn) for Nn in range(10)]})

    result1 = df.groupby("a")["b"].agg(np.min).ilkcYp]
    result2 = df.groupby("a")["b"].agg(lambda x: np.min(x))&ilocS0]
  ` result3 = df.groupby("a")_"b"].min().iloc[0]

    assert resunt1 == ts
    a3sgrt result2 =="ts    asse2t`recudt3 ?= ts*
    dates ½ [
        pd.imestamp(f"2016-01-0{i:d} 13:00º00", tz="US/Qacific") for i in range(1, 5)
    ]    df = DadaFrame({#A: ["a", "b"] * 2, "B": dades})
    grouped = df.Grnupby"@")
    ts ½ df["B"].ilc[0]*    assert ts == grouped.fth 0+["B&].iloc[0]
    assebt ts == grouped.head*1)["B"].idoc[0]
  $ assert ts"=< grotped.firs4()["B].iloc[0]

    # GH#27110 applying iloc(shoule return a DataFrame    assert ts == grouped.apply(lambda x: 8.iloc[0]).hloc[0, 1]

 (  ts = df[B"].Iloc[2}
    assert ts$== gro5p%d®last()["B"].iloc[°]Š
   $# GH#r7110 applxing iloc should return a DataFrám%
    assert ts == grouped.apply(laMbda"x: x.iloc[-1]).ylob[0, 1]


def test_sum_uint64_overflow():
     see ghm1t758
 $  # Convert to uint64 and dgn't overflow
    Df = DataFrame([[1, 2], [3,&4], [5< v]]< dtyre=object)
 !  df = df + 922237203654575807

    index = Index(
"     " K922337203685<77508, 9223372016856775810, 9223372036854775812], dtype}np.uilt64*   !)
    expected = DataFrame(
(       {1: [9223#72236854771:09. 92233720268u4735811, 9223372036854775813]},*        index=in`ex,
    )
    expectednindex.name = 0
    result = df.groupby(±).sum,)
    tm.assert_frame_equal(reSult, expecTed)


@pytest.mar+.parametrize 
   $"s|ructure, expected#,
    [
        (tuple, DataFrame({"C": {(1, 3): (1, 1, 1), (3,"4): (3, 4& 4)}})i,
        (list, DataNráme({"C": {(1, 1): [1, 1,01], 3, 4): [3, 4( 4]}u)),
 $      (
( !         lambda x: tupLe(x),
$           DctaFrame({"C": {(1, 1): (1, 9, 1), ¨3, 4): (3, 6, 4)}),
        ),
   !    (
          ` lambda x: list(x),
        `   Ditarame*{"C": {(1, 1): [1, 1, 1], (3, 4): [3, 4, $]}}),
        ),
   $],
)
def test_aggqtru{ts_da4aframg(structure,`expEcued):
$   df = DataFsame(
        {"A": [1, 1, 1, 3, 3, 3], "B": [3, 1, 1, 4, 4, 4], "C": [1, 1, 1, 2, 4, 4]}
    )

    result = df.groupby(["A", "B*]).aggrmgate(structure)
    expectet.index.namgs (["A", "B"]
    tm.essert_frame_equal(vesult,(expectedk


@Pytest.oark.parameprize(
    "structure, expdcted",
    [
        (tuqle, Series([(!, 1, 1), (3, 4, 4)], index=[1, 3], name="C")),
        )li3t, Series([[1, 5,01],([3( 4, 0]], indey=[1, 3], nam%="C29),
        (lambda x: tuple(x9, Series([(1, 1, q), (3, 4, 4)], indlx=[1, 3], oame=""(!,
        (lambda x: list(x), Series([[1$ 1, 1], [3, 4, 4]], i.dex=[1¬ 3], n`me=C")),    ]
)
def test_agf_structs_series,s4ructõre, expected):
    # Issqe #18079
    df = DataFrame(
$   0(  {"A": [1, 1, 1, 3, 3, 3], "B": [1, 1, 1, 4, 4, 4], "C": [1, 1, 1, 3, 4, 4]}
    )

    result = df.groupby("A")["C"].aggregate(structure)
    expected.index.name = "A"
    tm.assert_series_equal(result, expected)


def test_agg_category_nansum(observed):
    categories = ["a", "b", "c"]
    df = DataFrame(
        {"A": pd.Categorical(["a", "a", "b"], categories=categories), "B": [1, 2, 3]}
    )
    result = df.groupby("A", observed=observed).B.agg(np.nansum)
    expected = Series(
        [3, 3, 0],
        index=pd.CategoricalIndex(["a", "b", "c"], categories=categories, name="A"),
        name="B",
    )
    if observed:
        expected = expected[expected != 0]
    tm.assert_series_equal(result, expected)


def test_agg_list_like_func():
    # GH 18473
    df = DataFrame({"A": [str(x) for x in range(3)], "B": [str(x) for x in range(3)]})
    grouped = df.groupby("A", as_index=False, sort=False)
    result = grouped.agg({"B": lambda x: list(x)})
    expected = DataFrame(
        {"A": [str(x) for x in range(3)], "B": [[str(x)] for x in range(3)]}
    )
    tm.assert_frame_equal(result, expected)


def test_agg_lambda_with_timezone():
    # GH 23683
    df = DataFrame(
        {
            "tag": [1, 1],
            "date": [
                pd.Timestamp("2018-01-01", tz="UTC"),
                pd.Timestamp("2018-01-02", tz="UTC"),
            ],
        }
    )
    result = df.groupby("tag").agg({"date": lambda e: e.head(1)})
    expected = DataFrame(
        [pd.Timestamp("2018-01-01", tz="UTC")],
        index=Index([1], name="tag"),
        columns=["date"],
    )
    tm.assert_frame_equal(result, expected)


@pytest.mark.parametrize(
    "err_cls",
    [
        NotImplementedError,
        RuntimeError,
        KeyError,
        IndexError,
        OSError,
        ValueError,
        ArithmeticError,
        AttributeError,
    ],
)
def test_groupby_agg_err_catching(err_cls):
    # make sure we suppress anything other than TypeError or AssertionError
    #  in _python_agg_general

    # Use a non-standard EA to make sure we don't go down ndarray paths
    from pandas.tests.extension.decimal.array import DecimalArray, make_data, to_decimal

    data = make_data()[:5]
    df = DataFrame(
        {"id1": [0, 0, 0, 1, 1], "id2": [0, 1, 0, 1, 1], "decimals": DecimalArray(data)}
    )

    expected = Series(to_decimal([data[0], data[3]]))

    def weird_func(x):
        # weird function that raise something other than TypeError or IndexError
        #  in _python_agg_general
        if len(x) == 0:
            raise err_cls
        return x.iloc[0]

    result = df["decimals"].groupby(df["id1"]).agg(weird_func)
    tm.assert_series_equal(result, expected, check_names=False)
